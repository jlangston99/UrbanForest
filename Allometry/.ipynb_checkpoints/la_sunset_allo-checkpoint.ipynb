{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.collections import PatchCollection\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data and clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to file\n",
    "home = os.path.expanduser('~')\n",
    "path = f'{home}/UrbanForest/all_clean_LAcounty_sunset.hdf'\n",
    "\n",
    "# read the hdf\n",
    "la = pd.read_hdf(path, key='data')\n",
    "\n",
    "# select desired columns\n",
    "cols=['ID', 'LATITUDE', 'LONGITUDE', 'DBH_LO', 'DBH_HI', 'CREATED',\n",
    "      'UPDATED', 'SOURCE', 'Name_matched', 'Zone']\n",
    "la = la[cols]\n",
    "\n",
    "# drop NAs\n",
    "la.dropna(how='any', axis=0, subset=['DBH_LO', 'DBH_HI'], inplace=True)\n",
    "\n",
    "# capitalize genus names\n",
    "la['Name_matched'] = la.Name_matched.str.capitalize()\n",
    "\n",
    "# convert DBH to cm\n",
    "la['dbh_low']  = 2.54 * la.DBH_LO\n",
    "la['dbh_high'] = 2.54 * la.DBH_HI\n",
    "la.drop(['DBH_LO', 'DBH_HI'], axis=1, inplace=True)\n",
    "\n",
    "# Change date fields to dateTime type\n",
    "la['created'] = pd.to_datetime(la.CREATED)\n",
    "la['updated'] = pd.to_datetime(la.UPDATED)\n",
    "la.drop(['CREATED', 'UPDATED'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will first use allometric equations from :\n",
    "\n",
    " McPherson, E. Gregory; van Doorn, Natalie S.; Peper, Paula J. 2016. Urban tree database.\n",
    " Fort Collins, CO: Forest Service Research Data Archive. Updated 21 January 2020.\n",
    " https://doi.org/10.2737/RDS-2016-0005\n",
    "\n",
    " 'Apps min' and 'Apps max' give the input range (cm) that the authors feel \n",
    "  that the equations are reliable\n",
    " 'InlEmp' and 'SoCalC' are Climate zones where the eqs are different.\n",
    "  SoCalC reference city is Santa Monica, InlEmp is Claremont,\n",
    "  see Table 1, p16 for further Climate zone details.  \n",
    "  \n",
    "  After reading the equations and coefficients, we will get rid of trees that only occur a few times, and trees that we o not have equations for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 664155 entries, 0 to 1089845\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   ID            664155 non-null  int64         \n",
      " 1   LATITUDE      664155 non-null  float64       \n",
      " 2   LONGITUDE     664155 non-null  float64       \n",
      " 3   SOURCE        664155 non-null  object        \n",
      " 4   Name_matched  664155 non-null  object        \n",
      " 5   Zone          663384 non-null  float64       \n",
      " 6   dbh_low       664155 non-null  float64       \n",
      " 7   dbh_high      664155 non-null  float64       \n",
      " 8   created       28472 non-null   datetime64[ns]\n",
      " 9   updated       28472 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(5), int64(1), object(2)\n",
      "memory usage: 55.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# The equations\n",
    "def mcpherson_eqs():\n",
    "    '''returns dict of equations from table 3 (p24) of McPherson 2020\n",
    "    functions use np so as to be vectorized'''\n",
    "\n",
    "    eq_dict = {'lin'        : (lambda a, b, c, d, e, x, mse: a + b * (x)), \n",
    "                'quad'      : (lambda a, b, c, d, e, x, mse: a + b * x + c * x**2),\n",
    "                'cub'      : (lambda a, b, c, d, e, x, mse: a + b * x + c * x**2 + d * x**3),\n",
    "                'quart'     : (lambda a, b, c, d, e, x, mse:a + b * x + c *x**2 + d * x**3 + e * x**4), \n",
    "                'loglogw1' : (lambda a, b, c, d, e, x, mse: np.exp(a + b * np.log(np.log(x + 1) + (mse/2)))),\n",
    "                'loglogw2' : (lambda a, b, c, d, e, x, mse: np.exp(a + b * np.log(np.log(x + 1)) + (np.sqrt(x) + (mse/2)))),\n",
    "                'loglogw3' : (lambda a, b, c, d, e, x, mse: np.exp(a + b * np.log(np.log(x + 1)) + (x) + (mse/2))),\n",
    "                'loglogw4' : (lambda a, b, c, d, e, x, mse: np.exp(a + b * np.log(np.log(x + 1)) + (x**2) + (mse/2))),\n",
    "                'expow1'    : (lambda a, b, c, d, e, x, mse: np.exp(a+ b * (x) + (mse/2))),\n",
    "                'expow2'    : (lambda a, b, c, d, e, x, mse: np.exp(a + b * (x) + np.sqrt(x) + (mse/2))),\n",
    "                'expow3'    : (lambda a, b, c, d, e, x, mse: np.exp(a + b * (x) + (x) + (mse/2))),\n",
    "                'expow4'    : (lambda a, b, c, d, e, x, mse: np.exp(a + b * (x) + (x**2) + (mse/2)))}\n",
    "\n",
    "    return(eq_dict)\n",
    "\n",
    "eq_dict = mcpherson_eqs()\n",
    "\n",
    "# The cooeficients\n",
    "coef_df = pd.read_csv('TS6_Growth_coefficients.csvx',\n",
    "usecols=['Region', 'Scientific Name', 'Independent variable', 'Predicts component ', 'EqName', 'Units of predicted components',\n",
    "'EqName', 'a', 'b', 'c', 'd', 'e', 'Apps min', 'Apps max'])\n",
    "\n",
    "# Find all the trees with over 100 occurances in the dataset\n",
    "trees = la.Name_matched.value_counts()\n",
    "trees = list(trees.where(trees > 100).dropna().index)\n",
    "\n",
    "# drop trees we do not have equations for\n",
    "trees = [s for s in trees if s in coef_df['Scientific Name'].unique()]\n",
    "la = la.loc[la.Name_matched.isin(trees)]\n",
    "\n",
    "la.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The USGS lidar data is hosted on amazon, so we will nned the AWS client to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl \"https://s3.amazonaws.com/aws-cli/awscli-bundle.zip\" -o \"awscli-bundle.zip\"\n",
    "#!unzip awscli-bundle.zip \n",
    "#!./awscli-bundle/install -b ~/bin/aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a tmp directory too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tmp directory\n",
    "\n",
    "#! mkdir ~/tmp\n",
    "\n",
    "# make a variable for its path\n",
    "tmp = f'{home}/tmp'\n",
    "\n",
    "# make a variable with the path to aws cli\n",
    "aws = '~/bin/aws'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the top level ept json for the ```USGS_LPC_CA_LosAngeles_2016_LAS_2018``` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='~/bin/aws s3 cp s3://usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json /home/jovyan/tmp --no-sign-request', returncode=0, stdout=b'Completed 2.4 KiB/2.4 KiB (11.3 KiB/s) with 1 file(s) remaining\\rdownload: s3://usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json to ../tmp/ept.json\\n', stderr=b'')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "cmd = f'{aws} s3 cp s3://usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json {tmp} --no-sign-request'\n",
    "subprocess.run(cmd, shell=True, capture_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load ```ept.json``` and extract usefull information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authority': 'EPSG',\n",
       " 'horizontal': '3857',\n",
       " 'wkt': 'PROJCS[\"WGS 84 / Pseudo-Mercator\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Mercator_1SP\"],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],EXTENSION[\"PROJ4\",\"+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs\"],AUTHORITY[\"EPSG\",\"3857\"]]'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(f'{tmp}/ept.json') as f:\n",
    "    meta = json.load(f)\n",
    "    \n",
    "bounds = meta['bounds']\n",
    "bounds_conf = meta['boundsConforming']\n",
    "srs    = meta['srs']\n",
    "span   = meta['span']\n",
    "schema  = meta['schema']\n",
    "srs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output tells us the data is in EPSG:3857.  There is only a horizontal code present.  Lets reduce the srs to a more sueful form for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs = meta['srs']['authority'] + ':' + meta['srs']['horizontal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the srs is EPSG:3857 (Pseudo-Mercator) I don't think it necesaary to reproject.  We do need to use the scale and offset values to find absolute position according to ``read_value * scale + offset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_scale_offset(name, schema):\n",
    "    '''Retruns scale and offset for the spatial dimension given by name'''\n",
    "    for thing in schema:\n",
    "        if thing['name'] == name:\n",
    "            return(thing['scale'], thing['offset'])\n",
    "        \n",
    "x_scale, x_offset = bag_scale_offset('X', schema)\n",
    "y_scale, y_offset = bag_scale_offset('Y', schema)\n",
    "z_scale, z_offset = bag_scale_offset('Z', schema)\n",
    "\n",
    "def rescale(lon, lat, elev=None):\n",
    "    '''Returns point rescaled to the ept coords'''\n",
    "    x = lon * x_scale + x_offset\n",
    "    y = lat * y_scale + y_offset\n",
    "    if elev:\n",
    "        z = elev * z_scale + z_offset\n",
    "        return(x, y, z)\n",
    "    return(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.18467730111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-13168196.184677301"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_min = -118.467730111\n",
    "scaled = lon_min * x_scale\n",
    "print(scaled)\n",
    "sc_off = scaled + x_offset\n",
    "sc_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it should be possible to define a bounding box around a tree to query the pointcloud at that local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now we will ad 0.00007 degrees in each direction, this is jus a guess based on 5th decimal place ~ 1.1m\n",
    "# also not setting z max and min for the moment\n",
    "def make_scaled_bbox(lat, lon, bounds=None):\n",
    "    '''Returns a bbox in ept coords.\n",
    "    If present bounds is of form [xmin, ymin, zmin, xmax, ymax, zmax]'''\n",
    "    \n",
    "    buf = 0.00007\n",
    "    xmin = lon - buf\n",
    "    ymin = lat - buf\n",
    "    xmax = lon + buf\n",
    "    ymax = lat + buf\n",
    "    xmin, ymin = rescale(xmin, ymin)\n",
    "    xmax, ymax = rescale(xmax, ymax)\n",
    "\n",
    "    # make sure no bbox is out of the ept bbox\n",
    "    if bounds:\n",
    "        xmin = max(xmin, bounds[0])\n",
    "        ymin = max(ymin, bounds[1])\n",
    "        xmax = min(xmax, bounds[3])\n",
    "        ymax = min(ymax, bounds[4])\n",
    "    \n",
    "    return([xmin, xmax], [ymin, ymax])\n",
    "\n",
    "def make_bbox(lat, lon):\n",
    "    buf = 0.00007\n",
    "    xmin = lon - buf\n",
    "    ymin = lat - buf\n",
    "    xmax = lon + buf\n",
    "    ymax = lat + buf\n",
    "    return([xmin, xmax], [ymin, ymax])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will performa quick sanity check using the first entry of the LA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-13168196.184677301, -13168196.18291042], [4037456.3401063564, 4037456.3406509194])\n"
     ]
    }
   ],
   "source": [
    "minx = -118.467730111\n",
    "miny = 34.010635655\n",
    "maxx = -118.467445511\n",
    "maxy = 34.010856703\n",
    "minx, miny = rescale(minx, miny)\n",
    "maxx, maxy = rescale(-118.291042065, 34.065091929)\n",
    "temp_box = ([minx, maxx], [miny, maxy])\n",
    "print(temp_box)\n",
    "tbbox = ([-13168200.284677301, -13168197.28291042], [4037456.3401063564, 4037459.3406509194])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try to get the point cloud within the bbox using PDALs ept reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdal\n",
    "from string import Template\n",
    "from tqdm import tqdm\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-118.066793605"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 1986759\n",
    "lat = la.loc[la.ID==id]['LATITUDE'].values[0]\n",
    "lon = la.loc[la.ID==id]['LONGITUDE'].values[0]\n",
    "lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-b101fd3df172>\", line 2, in <module>\n",
      "    subprocess.run(cmd, shell=True, capture_output=True)\n",
      "  File \"/opt/conda/lib/python3.8/subprocess.py\", line 491, in run\n",
      "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.8/subprocess.py\", line 1024, in communicate\n",
      "    stdout, stderr = self._communicate(input, endtime, timeout)\n",
      "  File \"/opt/conda/lib/python3.8/subprocess.py\", line 1866, in _communicate\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 166, in islink\n",
      "    try:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-b101fd3df172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{aws} s3 cp s3://usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json {tmp} --no-sign-request'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1866\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1867\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "cmd = f'{aws} s3 cp s3://usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json {tmp} --no-sign-request'\n",
    "subprocess.run(cmd, shell=True, capture_output=True)\n",
    "\n",
    "print('ept.json read from s3 ...')\n",
    "\n",
    "with open(f'{tmp}/ept.json') as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "    \n",
    "print('metadata bagged ...')\n",
    "bounds = meta['bounds']\n",
    "bounds_conf = meta['boundsConforming']\n",
    "srs = meta['srs']['authority'] + ':' + meta['srs']['horizontal']\n",
    "\n",
    "span   = meta['span']\n",
    "schema  = meta['schema']\n",
    "\n",
    "x_scale, x_offset = bag_scale_offset('X', schema)\n",
    "y_scale, y_offset = bag_scale_offset('Y', schema)\n",
    "z_scale, z_offset = bag_scale_offset('Z', schema)\n",
    "\n",
    "\n",
    "scaled_bbox = make_scaled_bbox(lat, lon, bounds=bounds_conf)\n",
    "\n",
    "def bbox_geojson(lat, lon, filename):\n",
    "    '''makes wgs84 bbox as geojson for comparison in gis'''\n",
    "    [xmin, xmax], [ymin, ymax] = make_bbox(lat, lon)\n",
    "    gjson = {'coordinates' : [[[xmin, ymin], [xmin, ymax], [xmax, ymax], [xmax, ymin]]],\n",
    "            'type' : 'Polygon'}\n",
    "    with open(filename, 'w') as of:\n",
    "        json.dump(gjson, of)\n",
    "\n",
    "bbox_geojson(lat, lon, 'xxx.json')        \n",
    "print('geojson written ...')\n",
    "\n",
    "# make and validate pipeline\n",
    "t = Template('''\n",
    "{\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "\"bounds\": \"([-10425171.940, -10425171.000], [5164494.710, 5164595.200])\",\n",
    "\"filename\": \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json\",\n",
    "\"type\": \"readers.ept\",\n",
    "\"tag\": \"readdata\"\n",
    "        },\n",
    "        {\n",
    "            \"out_srs\": \"EPSG:4326\",\n",
    "            \"tag\": \"reprojectwgs84\",\n",
    "            \"type\": \"filters.reprojection\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"xxx.laz\",\n",
    "            \"inputs\": [ \"reprojectwgs84\" ],\n",
    "            \"tag\": \"writerslas\",\n",
    "            \"type\": \"writers.las\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"xxx.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"inputs\": [ \"writerslas\" ],\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\": 1,\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6\n",
    "        }\n",
    "    ]\n",
    "}''')\n",
    "\n",
    "pipe = t.substitute(scaled_bbox=scaled_bbox)\n",
    "print('pipeline json written ...')\n",
    "pipeline = pdal.Pipeline(pipe)\n",
    "print('pipeline string truned into pipeline ...')\n",
    "pipeline.validate()\n",
    "print('pipeline validated ...')\n",
    "\n",
    " # execuite pipeline\n",
    "count = pipeline.execute()\n",
    "print('pipeline executed ...')\n",
    "S = pipeline.arrays[0]\n",
    "metadata = pipeline.metadata\n",
    "log = pipeline.log\n",
    "\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-15-5c063dddf927>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-5c063dddf927>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    [\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "@delayed\n",
    "def row_bounds_ept_query(i):\n",
    "    # get lat lon of first entry\n",
    "    row = la.iloc[i]\n",
    "    ident = row['ID']\n",
    "    lat = row['LATITUDE']\n",
    "    lon = row['LONGITUDE']\n",
    "\n",
    "    # make bbox in the ept coord system\n",
    "    scaled_bbox = make_scaled_bbox(lat, lon, bounds=bounds_conf)\n",
    "    \n",
    "    # sanity check will raise erros if scalled bbox is not in the ept bounds\n",
    "    assert (scaled_bbox[0][0] > bounds[0]) & (scaled_bbox[0][1] < bounds[3])\n",
    "    assert (scaled_bbox[1][0] > bounds[1]) & (scaled_bbox[1][1] < bounds[4])\n",
    "    \n",
    "    # make and validate pipeline\n",
    "    t = Template('''\n",
    "    [\n",
    "        {\n",
    "            \"type\": \"readers.ept\",\n",
    "            \"filename\": \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json\",\n",
    "            \"bounds\": \"${scaled_bbox}\",\n",
    "            \"resolution\": 1\n",
    "        }\n",
    "    ]''')\n",
    "\n",
    "    pipe = t.substitute(scaled_bbox=tbbox)\n",
    "    pipeline = pdal.Pipeline(pipe)\n",
    "    pipeline.validate()\n",
    "    \n",
    "    # execuite pipeline\n",
    "    count = pipeline.execute()\n",
    "    S = pipeline.arrays[0]\n",
    "    metadata = pipeline.metadata\n",
    "    log = pipeline.log\n",
    "    \n",
    "    # do stuff\n",
    "    sh = S.shape\n",
    "    if sh[0] > 0:\n",
    "        print(f'{ident} is a numpy structured array of shape {sh}.')\n",
    "        return(S)\n",
    "        \n",
    "results = []\n",
    "for i in range(1):\n",
    "    results.append(row_bounds_ept_query(i+10))\n",
    "    \n",
    "with ProgressBar():\n",
    "    S = compute(*results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
