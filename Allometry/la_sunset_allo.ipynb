{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.collections import PatchCollection\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data and clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to file\n",
    "home = os.path.expanduser('~')\n",
    "path = f'{home}/UrbanForest/all_clean_LAcounty_sunset.hdf'\n",
    "\n",
    "# read the hdf\n",
    "la = pd.read_hdf(path, key='data')\n",
    "\n",
    "# select desired columns\n",
    "cols=['ID', 'LATITUDE', 'LONGITUDE', 'DBH_LO', 'DBH_HI', 'CREATED',\n",
    "      'UPDATED', 'SOURCE', 'Name_matched', 'Zone']\n",
    "la = la[cols]\n",
    "\n",
    "# drop NAs\n",
    "la.dropna(how='any', axis=0, subset=['DBH_LO', 'DBH_HI'], inplace=True)\n",
    "\n",
    "# capitalize genus names\n",
    "la['Name_matched'] = la.Name_matched.str.capitalize()\n",
    "\n",
    "# convert DBH to cm\n",
    "la['dbh_low']  = 2.54 * la.DBH_LO\n",
    "la['dbh_high'] = 2.54 * la.DBH_HI\n",
    "la.drop(['DBH_LO', 'DBH_HI'], axis=1, inplace=True)\n",
    "\n",
    "# Change date fields to dateTime type\n",
    "la['created'] = pd.to_datetime(la.CREATED)\n",
    "la['updated'] = pd.to_datetime(la.UPDATED)\n",
    "la.drop(['CREATED', 'UPDATED'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will first use allometric equations from :\n",
    "\n",
    " McPherson, E. Gregory; van Doorn, Natalie S.; Peper, Paula J. 2016. Urban tree database.\n",
    " Fort Collins, CO: Forest Service Research Data Archive. Updated 21 January 2020.\n",
    " https://doi.org/10.2737/RDS-2016-0005\n",
    "\n",
    " 'Apps min' and 'Apps max' give the input range (cm) that the authors feel \n",
    "  that the equations are reliable\n",
    " 'InlEmp' and 'SoCalC' are Climate zones where the eqs are different.\n",
    "  SoCalC reference city is Santa Monica, InlEmp is Claremont,\n",
    "  see Table 1, p16 for further Climate zone details.  \n",
    "  \n",
    "  After reading the equations and coefficients, we will get rid of trees that only occur a few times, and trees that we o not have equations for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 664155 entries, 0 to 1089845\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   ID            664155 non-null  int64         \n",
      " 1   LATITUDE      664155 non-null  float64       \n",
      " 2   LONGITUDE     664155 non-null  float64       \n",
      " 3   SOURCE        664155 non-null  object        \n",
      " 4   Name_matched  664155 non-null  object        \n",
      " 5   Zone          663384 non-null  float64       \n",
      " 6   dbh_low       664155 non-null  float64       \n",
      " 7   dbh_high      664155 non-null  float64       \n",
      " 8   created       28472 non-null   datetime64[ns]\n",
      " 9   updated       28472 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(5), int64(1), object(2)\n",
      "memory usage: 55.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# The equations\n",
    "def mcpherson_eqs():\n",
    "    '''returns dict of equations from table 3 (p24) of McPherson 2020\n",
    "    functions use np so as to be vectorized'''\n",
    "\n",
    "    eq_dict = {'lin'        : (lambda a, b, c, d, e, x, mse: a + b * (x)), \n",
    "                'quad'      : (lambda a, b, c, d, e, x, mse: a + b * x + c * x**2),\n",
    "                'cub'      : (lambda a, b, c, d, e, x, mse: a + b * x + c * x**2 + d * x**3),\n",
    "                'quart'     : (lambda a, b, c, d, e, x, mse:a + b * x + c *x**2 + d * x**3 + e * x**4), \n",
    "                'loglogw1' : (lambda a, b, c, d, e, x, mse: np.exp(a + b * np.log(np.log(x + 1) + (mse/2)))),\n",
    "                'loglogw2' : (lambda a, b, c, d, e, x, mse: np.exp(a + b * np.log(np.log(x + 1)) + (np.sqrt(x) + (mse/2)))),\n",
    "                'loglogw3' : (lambda a, b, c, d, e, x, mse: np.exp(a + b * np.log(np.log(x + 1)) + (x) + (mse/2))),\n",
    "                'loglogw4' : (lambda a, b, c, d, e, x, mse: np.exp(a + b * np.log(np.log(x + 1)) + (x**2) + (mse/2))),\n",
    "                'expow1'    : (lambda a, b, c, d, e, x, mse: np.exp(a+ b * (x) + (mse/2))),\n",
    "                'expow2'    : (lambda a, b, c, d, e, x, mse: np.exp(a + b * (x) + np.sqrt(x) + (mse/2))),\n",
    "                'expow3'    : (lambda a, b, c, d, e, x, mse: np.exp(a + b * (x) + (x) + (mse/2))),\n",
    "                'expow4'    : (lambda a, b, c, d, e, x, mse: np.exp(a + b * (x) + (x**2) + (mse/2)))}\n",
    "\n",
    "    return(eq_dict)\n",
    "\n",
    "eq_dict = mcpherson_eqs()\n",
    "\n",
    "# The cooeficients\n",
    "coef_df = pd.read_csv('TS6_Growth_coefficients.csvx',\n",
    "usecols=['Region', 'Scientific Name', 'Independent variable', 'Predicts component ', 'EqName', 'Units of predicted components',\n",
    "'EqName', 'a', 'b', 'c', 'd', 'e', 'Apps min', 'Apps max'])\n",
    "\n",
    "# Find all the trees with over 100 occurances in the dataset\n",
    "trees = la.Name_matched.value_counts()\n",
    "trees = list(trees.where(trees > 100).dropna().index)\n",
    "\n",
    "# drop trees we do not have equations for\n",
    "trees = [s for s in trees if s in coef_df['Scientific Name'].unique()]\n",
    "la = la.loc[la.Name_matched.isin(trees)]\n",
    "\n",
    "la.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The USGS lidar data is hosted on amazon, so we will nned the AWS client to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 16.8M  100 16.8M    0     0  13.6M      0  0:00:01  0:00:01 --:--:-- 13.6M\n",
      "Archive:  awscli-bundle.zip\n",
      "  inflating: awscli-bundle/install   \n",
      "  inflating: awscli-bundle/packages/rsa-3.4.2.tar.gz  \n",
      "  inflating: awscli-bundle/packages/docutils-0.15.2.tar.gz  \n",
      "  inflating: awscli-bundle/packages/futures-3.3.0.tar.gz  \n",
      "  inflating: awscli-bundle/packages/PyYAML-5.2.tar.gz  \n",
      "  inflating: awscli-bundle/packages/colorama-0.4.1.tar.gz  \n",
      "  inflating: awscli-bundle/packages/urllib3-1.25.7.tar.gz  \n",
      "  inflating: awscli-bundle/packages/six-1.15.0.tar.gz  \n",
      "  inflating: awscli-bundle/packages/botocore-1.19.57.tar.gz  \n",
      "  inflating: awscli-bundle/packages/jmespath-0.10.0.tar.gz  \n",
      "  inflating: awscli-bundle/packages/virtualenv-16.7.8.tar.gz  \n",
      "  inflating: awscli-bundle/packages/colorama-0.4.3.tar.gz  \n",
      "  inflating: awscli-bundle/packages/awscli-1.18.217.tar.gz  \n",
      "  inflating: awscli-bundle/packages/urllib3-1.26.2.tar.gz  \n",
      "  inflating: awscli-bundle/packages/PyYAML-5.3.1.tar.gz  \n",
      "  inflating: awscli-bundle/packages/python-dateutil-2.8.0.tar.gz  \n",
      "  inflating: awscli-bundle/packages/s3transfer-0.3.4.tar.gz  \n",
      "  inflating: awscli-bundle/packages/pyasn1-0.4.8.tar.gz  \n",
      "  inflating: awscli-bundle/packages/setup/wheel-0.33.6.tar.gz  \n",
      "  inflating: awscli-bundle/packages/setup/setuptools_scm-3.3.3.tar.gz  \n",
      "Running cmd: /opt/conda/bin/python -m venv /home/jovyan/.local/lib/aws\n",
      "Running cmd: /home/jovyan/.local/lib/aws/bin/pip install --no-binary :all: --no-cache-dir --no-index --find-links file://. setuptools_scm-3.3.3.tar.gz\n",
      "Running cmd: /home/jovyan/.local/lib/aws/bin/pip install --no-binary :all: --no-cache-dir --no-index --find-links file://. wheel-0.33.6.tar.gz\n",
      "Running cmd: /home/jovyan/.local/lib/aws/bin/pip install --no-binary :all: --no-build-isolation --no-cache-dir --no-index  --find-links file:///home/jovyan/Allometry/awscli-bundle/packages awscli-1.18.217.tar.gz\n",
      "You can now run: /home/jovyan/bin/aws --version\n",
      "\n",
      "Note: AWS CLI version 2, the latest major version of the AWS CLI, is now stable and recommended for general use. For more information, see the AWS CLI version 2 installation instructions at: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html\n"
     ]
    }
   ],
   "source": [
    "!curl \"https://s3.amazonaws.com/aws-cli/awscli-bundle.zip\" -o \"awscli-bundle.zip\"\n",
    "!unzip awscli-bundle.zip \n",
    "!./awscli-bundle/install -b ~/bin/aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a tmp directory too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/jovyan/tmp’: File exists\n"
     ]
    }
   ],
   "source": [
    "# make a tmp directory\n",
    "\n",
    "! mkdir ~/tmp\n",
    "\n",
    "# make a variable for its path\n",
    "tmp = f'{home}/tmp'\n",
    "\n",
    "# make a variable with the path to aws cli\n",
    "aws = '~/bin/aws'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the top level ept json for the ```USGS_LPC_CA_LosAngeles_2016_LAS_2018``` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='~/bin/aws s3 cp s3://usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json /home/jovyan/tmp --no-sign-request', returncode=0, stdout=b'Completed 2.4 KiB/2.4 KiB (5.7 KiB/s) with 1 file(s) remaining\\rdownload: s3://usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json to ../tmp/ept.json\\n', stderr=b'')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "cmd = f'{aws} s3 cp s3://usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json {tmp} --no-sign-request'\n",
    "subprocess.run(cmd, shell=True, capture_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load ```ept.json``` and extract usefull information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'{tmp}/ept.json') as f:\n",
    "    meta = json.load(f)\n",
    "    \n",
    "bounds = meta['bounds']\n",
    "bounds_conf = meta['boundsConforming']\n",
    "srs    = meta['srs']\n",
    "span   = meta['span']\n",
    "schema  = meta['schema']\n",
    "srs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output tells us the data is in EPSG:3857.  There is only a horizontal code present.  Lets reduce the srs to a more sueful form for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs = meta['srs']['authority'] + ':' + meta['srs']['horizontal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the srs is EPSG:3857 (Pseudo-Mercator) I don't think it necesaary to reproject.  We do need to use the scale and offset values to find absolute position according to ``read_value * scale + offset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_scale_offset(name, schema):\n",
    "    '''Retruns scale and offset for the spatial dimension given by name'''\n",
    "    for thing in schema:\n",
    "        if thing['name'] == name:\n",
    "            return(thing['scale'], thing['offset'])\n",
    "        \n",
    "x_scale, x_offset = bag_scale_offset('X', schema)\n",
    "y_scale, y_offset = bag_scale_offset('Y', schema)\n",
    "z_scale, z_offset = bag_scale_offset('Z', schema)\n",
    "\n",
    "def rescale(lon, lat, elev=None):\n",
    "    '''Returns point rescaled to the ept coords'''\n",
    "    x = lon * x_scale + x_offset\n",
    "    y = lat * y_scale + y_offset\n",
    "    if elev:\n",
    "        z = elev * z_scale + z_offset\n",
    "        return(x, y, z)\n",
    "    return(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.18467730111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-13168196.184677301"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_min = -118.467730111\n",
    "scaled = lon_min * x_scale\n",
    "print(scaled)\n",
    "sc_off = scaled + x_offset\n",
    "sc_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it should be possible to define a bounding box around a tree to query the pointcloud at that local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now we will ad 0.00007 degrees in each direction, this is jus a guess based on 5th decimal place ~ 1.1m\n",
    "# also not setting z max and min for the moment\n",
    "def make_scaled_bbox(lat, lon, bounds=None):\n",
    "    '''Returns a bbox in ept coords.\n",
    "    If present bounds is of form [xmin, ymin, zmin, xmax, ymax, zmax]'''\n",
    "    \n",
    "    buf = 0.00007\n",
    "    xmin = lon - buf\n",
    "    ymin = lat - buf\n",
    "    xmax = lon + buf\n",
    "    ymax = lat + buf\n",
    "    xmin, ymin = rescale(xmin, ymin)\n",
    "    xmax, ymax = rescale(xmax, ymax)\n",
    "\n",
    "    # make sure no bbox is out of the ept bbox\n",
    "    if bounds:\n",
    "        xmin = max(xmin, bounds[0])\n",
    "        ymin = max(ymin, bounds[1])\n",
    "        xmax = min(xmax, bounds[3])\n",
    "        ymax = min(ymax, bounds[4])\n",
    "    \n",
    "    return([xmin, xmax], [ymin, ymax])\n",
    "\n",
    "def make_bbox(lat, lon):\n",
    "    buf = 0.00007\n",
    "    xmin = lon - buf\n",
    "    ymin = lat - buf\n",
    "    xmax = lon + buf\n",
    "    ymax = lat + buf\n",
    "    return([xmin, xmax], [ymin, ymax])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will performa quick sanity check using the first entry of the LA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-13168196.184677301, -13168196.18291042], [4037456.3401063564, 4037456.3406509194])\n"
     ]
    }
   ],
   "source": [
    "minx = -118.467730111\n",
    "miny = 34.010635655\n",
    "maxx = -118.467445511\n",
    "maxy = 34.010856703\n",
    "minx, miny = rescale(minx, miny)\n",
    "maxx, maxy = rescale(-118.291042065, 34.065091929)\n",
    "temp_box = ([minx, maxx], [miny, maxy])\n",
    "print(temp_box)\n",
    "tbbox = ([-13168200.284677301, -13168197.28291042], [4037456.3401063564, 4037459.3406509194])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdal\n",
      "  Downloading PDAL-2.3.7.tar.gz (945 kB)\n",
      "\u001b[K     |████████████████████████████████| 945 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pdal\n",
      "  Building wheel for pdal (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pdal: filename=PDAL-2.3.7-cp38-cp38-linux_x86_64.whl size=325272 sha256=118a4c23e85e41b4da8371a0365f7745553de46593ca510b9ecb4dc690f47246\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/49/48/b4/3f9a021e4d674d9aa44dd61989d53d3add21ad6d69b288235a\n",
      "Successfully built pdal\n",
      "Installing collected packages: pdal\n",
      "Successfully installed pdal-2.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try to get the point cloud within the bbox using PDALs ept reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdal\n",
    "from string import Template\n",
    "from tqdm import tqdm\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed |  0.3s712181 is a numpy structured array of shape (32,).\n",
      "[########################################] | 100% Completed |  3.8s\n"
     ]
    }
   ],
   "source": [
    "@delayed\n",
    "def row_bounds_ept_query(i):\n",
    "    # get lat lon of first entry\n",
    "    row = la.iloc[i]\n",
    "    ident = row['ID']\n",
    "    lat = row['LATITUDE']\n",
    "    lon = row['LONGITUDE']\n",
    "\n",
    "    # make bbox in the ept coord system\n",
    "    scaled_bbox = make_scaled_bbox(lat, lon, bounds=bounds_conf)\n",
    "    \n",
    "    # sanity check will raise erros if scalled bbox is not in the ept bounds\n",
    "    assert (scaled_bbox[0][0] > bounds[0]) & (scaled_bbox[0][1] < bounds[3])\n",
    "    assert (scaled_bbox[1][0] > bounds[1]) & (scaled_bbox[1][1] < bounds[4])\n",
    "    \n",
    "    # make and validate pipeline\n",
    "    t = Template('''\n",
    "    [\n",
    "        {\n",
    "            \"type\": \"readers.ept\",\n",
    "            \"filename\": \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json\",\n",
    "            \"bounds\": \"${scaled_bbox}\",\n",
    "            \"resolution\": 1\n",
    "        }\n",
    "    ]''')\n",
    "\n",
    "    pipe = t.substitute(scaled_bbox=tbbox)\n",
    "    pipeline = pdal.Pipeline(pipe)\n",
    "    pipeline.validate()\n",
    "    \n",
    "    # execuite pipeline\n",
    "    count = pipeline.execute()\n",
    "    S = pipeline.arrays[0]\n",
    "    metadata = pipeline.metadata\n",
    "    log = pipeline.log\n",
    "    \n",
    "    # do stuff\n",
    "    sh = S.shape\n",
    "    if sh[0] > 0:\n",
    "        print(f'{ident} is a numpy structured array of shape {sh}.')\n",
    "        return(S)\n",
    "        \n",
    "results = []\n",
    "for i in range(1):\n",
    "    results.append(row_bounds_ept_query(i+10))\n",
    "    \n",
    "with ProgressBar():\n",
    "    S = compute(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-13271559, 3934093, -102275, -13064831, 4140821, 104453]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.8/site-packages/pdal/pipeline.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': [-13271559, 3934093, -102275, -13064831, 4140821, 104453],\n",
       " 'boundsConforming': [-13241541, 3934094, -1179, -13094849, 4140819, 3356],\n",
       " 'dataType': 'laszip',\n",
       " 'hierarchyType': 'json',\n",
       " 'points': 75242414417,\n",
       " 'schema': [{'name': 'X',\n",
       "   'offset': -13168195,\n",
       "   'scale': 0.01,\n",
       "   'size': 4,\n",
       "   'type': 'signed'},\n",
       "  {'name': 'Y', 'offset': 4037456, 'scale': 0.01, 'size': 4, 'type': 'signed'},\n",
       "  {'name': 'Z', 'offset': 1089, 'scale': 0.01, 'size': 4, 'type': 'signed'},\n",
       "  {'name': 'Intensity', 'size': 2, 'type': 'unsigned'},\n",
       "  {'name': 'ReturnNumber', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'NumberOfReturns', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'ScanDirectionFlag', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'EdgeOfFlightLine', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'Classification', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'ScanAngleRank', 'size': 4, 'type': 'float'},\n",
       "  {'name': 'UserData', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'PointSourceId', 'size': 2, 'type': 'unsigned'},\n",
       "  {'name': 'GpsTime', 'size': 8, 'type': 'float'},\n",
       "  {'name': 'ScanChannel', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'ClassFlags', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'OriginId', 'size': 4, 'type': 'unsigned'}],\n",
       " 'span': 256,\n",
       " 'srs': {'authority': 'EPSG',\n",
       "  'horizontal': '3857',\n",
       "  'wkt': 'PROJCS[\"WGS 84 / Pseudo-Mercator\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Mercator_1SP\"],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],EXTENSION[\"PROJ4\",\"+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs\"],AUTHORITY[\"EPSG\",\"3857\"]]'},\n",
       " 'version': '1.0.0'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOWA #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-118.38393940968001"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 1919622\n",
    "lat = la.loc[la.ID==712126]['LATITUDE'].values[0]\n",
    "lon = la.loc[la.ID==712126]['LONGITUDE'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmd = f'{aws} s3 cp s3://usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json {tmp} --no-sign-request'\n",
    "subprocess.run(cmd, shell=True, capture_output=True)\n",
    "\n",
    "with open(f'{tmp}/ept.json') as f:\n",
    "    meta = json.load(f)\n",
    "    \n",
    "bounds = meta['bounds']\n",
    "bounds_conf = meta['boundsConforming']\n",
    "srs = meta['srs']['authority'] + ':' + meta['srs']['horizontal']\n",
    "\n",
    "span   = meta['span']\n",
    "schema  = meta['schema']\n",
    "\n",
    "x_scale, x_offset = bag_scale_offset('X', schema)\n",
    "y_scale, y_offset = bag_scale_offset('Y', schema)\n",
    "z_scale, z_offset = bag_scale_offset('Z', schema)\n",
    "\n",
    "\n",
    "scaled_bbox = make_scaled_bbox(lat, lon, bounds=bounds_conf)\n",
    "\n",
    "def bbox_geojson(lat, lon, filename):\n",
    "    '''makes wgs84 bbox as geojson for comparison in gis'''\n",
    "    [xmin, xmax], [ymin, ymax] = make_bbox(lat, lon)\n",
    "    gjson = {'coordinates' : [[[xmin, ymin], [xmin, ymax], [xmax, ymax], [xmax, ymin]]],\n",
    "            'type' : 'Polygon'}\n",
    "    with open(filename, 'w') as of:\n",
    "        json.dump(gjson, of)\n",
    "\n",
    "bbox_geojson(lat, lon, 'xxx.json')        \n",
    "        \n",
    "# make and validate pipeline\n",
    "t = Template('''\n",
    "{\n",
    "    \"pipeline\": [\n",
    "        {\n",
    "\"bounds\": \"([-10425171.940, -10425171.000], [5164494.710, 5164595.200])\",\n",
    "\"filename\": \"https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_LosAngeles_2016_LAS_2018/ept.json\",\n",
    "\"type\": \"readers.ept\",\n",
    "\"tag\": \"readdata\"\n",
    "        },\n",
    "        {\n",
    "            \"limits\": \"Classification![7:7]\",\n",
    "            \"type\": \"filters.range\",\n",
    "            \"tag\": \"nonoise\"\n",
    "        },\n",
    "        {\n",
    "            \"assignment\": \"Classification[:]=0\",\n",
    "            \"tag\": \"wipeclasses\",\n",
    "            \"type\": \"filters.assign\"\n",
    "        },\n",
    "        {\n",
    "            \"out_srs\": \"EPSG:4326\",\n",
    "            \"tag\": \"reprojectwgs84\",\n",
    "            \"type\": \"filters.reprojection\"\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"groundify\",\n",
    "            \"type\": \"filters.smrf\"\n",
    "        },\n",
    "        {\n",
    "            \"limits\": \"Classification[2:2]\",\n",
    "            \"type\": \"filters.range\",\n",
    "            \"tag\": \"classify\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"xxx.laz\",\n",
    "            \"inputs\": [ \"classify\" ],\n",
    "            \"tag\": \"writerslas\",\n",
    "            \"type\": \"writers.las\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"xxx.tif\",\n",
    "            \"gdalopts\": \"tiled=yes,     compress=deflate\",\n",
    "            \"inputs\": [ \"writerslas\" ],\n",
    "            \"nodata\": -9999,\n",
    "            \"output_type\": \"idw\",\n",
    "            \"resolution\": 1,\n",
    "            \"type\": \"writers.gdal\",\n",
    "            \"window_size\": 6\n",
    "        }\n",
    "    ]\n",
    "}''')\n",
    "\n",
    "pipe = t.substitute(scaled_bbox=tbbox)\n",
    "pipeline = pdal.Pipeline(pipe)\n",
    "pipeline.validate()\n",
    "\n",
    " # execuite pipeline\n",
    "count = pipeline.execute()\n",
    "S = pipeline.arrays[0]\n",
    "metadata = pipeline.metadata\n",
    "log = pipeline.log\n",
    "\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-13168195.937270697, -13168195.937269298],\n",
       " [4037456.4158676276, 4037456.4158690274])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': [-10758075, 4793202, -361911, -10034133, 5517144, 362031],\n",
       " 'boundsConforming': [-10758074, 4920531, -1897, -10034134, 5389814, 2017],\n",
       " 'dataType': 'laszip',\n",
       " 'hierarchyType': 'json',\n",
       " 'points': 167692896718,\n",
       " 'reprojection': {'in': 'EPSG:26915', 'out': 'EPSG:3857'},\n",
       " 'schema': [{'name': 'X',\n",
       "   'offset': -10396104,\n",
       "   'scale': 0.01,\n",
       "   'size': 4,\n",
       "   'type': 'signed'},\n",
       "  {'name': 'Y', 'offset': 5155173, 'scale': 0.01, 'size': 4, 'type': 'signed'},\n",
       "  {'name': 'Z', 'offset': 60, 'scale': 0.01, 'size': 4, 'type': 'signed'},\n",
       "  {'name': 'Intensity', 'size': 2, 'type': 'unsigned'},\n",
       "  {'name': 'ReturnNumber', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'NumberOfReturns', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'ScanDirectionFlag', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'EdgeOfFlightLine', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'Classification', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'ScanAngleRank', 'size': 4, 'type': 'float'},\n",
       "  {'name': 'UserData', 'size': 1, 'type': 'unsigned'},\n",
       "  {'name': 'PointSourceId', 'size': 2, 'type': 'unsigned'},\n",
       "  {'name': 'GpsTime', 'size': 8, 'type': 'float'},\n",
       "  {'name': 'OriginId', 'size': 4, 'type': 'unsigned'}],\n",
       " 'srs': {'authority': 'EPSG',\n",
       "  'horizontal': '3857',\n",
       "  'wkt': 'PROJCS[\"WGS 84 / Pseudo-Mercator\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Mercator_1SP\"],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],EXTENSION[\"PROJ4\",\"+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs\"],AUTHORITY[\"EPSG\",\"3857\"]]'},\n",
       " 'version': '1.0.0',\n",
       " 'span': 256}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
